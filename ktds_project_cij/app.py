import streamlit as st
import json
import os
from docx import Document
import zipfile

# JSON íŒŒì¼ ê²½ë¡œ
DATA_PATH = "streamlit_data/ia_acs_documents.json"
WORD_DOCS_DIR = "streamlit_data/ia_word_documents_50"

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def load_data():
    if os.path.exists(DATA_PATH):
        with open(DATA_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

data = load_data()

# IA ë¬¸ì„œë²ˆí˜¸ ìƒì„±ê¸°: í˜„ì¬ ë¬¸ì„œ ìˆ˜ ê¸°ì¤€ +1
def get_next_doc_id():
    return f"{len(data) + 1:03d}"

st.set_page_config(page_title="IA ë¬¸ì„œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.sidebar.title("ğŸ“ IA ë¬¸ì„œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# â¬†ï¸ ê¸°ëŠ¥ 2: IA ë¬¸ì„œ ì—…ë¡œë“œ
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“¤ IA ë¬¸ì„œ ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader("IA Word ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["docx"])
if uploaded_file is not None:
    new_id = get_next_doc_id()
    save_filename = f"{new_id}_{uploaded_file.name}"
    save_path = os.path.join(WORD_DOCS_DIR, save_filename)
    with open(save_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    # Word ë¬¸ì„œ íŒŒì‹± ë° JSON ë³€í™˜
    docx = Document(save_path)
    paragraphs = [p.text.strip() for p in docx.paragraphs if p.text.strip()]

    parsed = {
        "id": new_id,
        "project_title": paragraphs[1].replace("ê³¼ì œëª…: ", "") if len(paragraphs) > 1 else "ì—…ë¡œë“œ ë¬¸ì„œ",
        "requirement": next((p for p in paragraphs if p.startswith("ìš”êµ¬ì‚¬í•­:")), "ìš”êµ¬ì‚¬í•­: ì—†ìŒ").replace("ìš”êµ¬ì‚¬í•­:", "").strip(),
        "parts": []
    }

    for i in range(len(paragraphs)):
        if paragraphs[i].startswith("[ì—°ê´€ íŒŒíŠ¸"):
            part = {
                "part_name": paragraphs[i + 1].replace("- íŒŒíŠ¸ ì´ë¦„: ", ""),
                "role": paragraphs[i + 2].replace("- êµ¬ë¶„: ", ""),
                "feature": paragraphs[i + 3].replace("- ê¸°ëŠ¥: ", ""),
                "content": paragraphs[i + 4].replace("- ë‚´ìš©: ", "")
            }
            parsed["parts"].append(part)

    data.append(parsed)
    with open(DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    st.sidebar.success(f"âœ… ì—…ë¡œë“œ ë° ë“±ë¡ ì™„ë£Œ: {save_filename} (ID: {new_id})")

# â¬‡ï¸ ì „ì²´ Word ë¬¸ì„œ ì••ì¶• ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“¦ ì „ì²´ IA ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ")
zip_path = "streamlit_data/ia_word_documents_all.zip"
with zipfile.ZipFile(zip_path, "w") as zipf:
    for fname in os.listdir(WORD_DOCS_DIR):
        fpath = os.path.join(WORD_DOCS_DIR, fname)
        zipf.write(fpath, arcname=fname)
with open(zip_path, "rb") as f:
    st.sidebar.download_button(
        label="ğŸ“ ì „ì²´ ë¬¸ì„œ ì••ì¶• ë‹¤ìš´ë¡œë“œ",
        data=f,
        file_name="ia_word_documents_all.zip",
        mime="application/zip"
    )

st.title("ğŸ“Š AI ê¸°ë°˜ IA ë¬¸ì„œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# í‚¤ì›Œë“œ ê²€ìƒ‰
search_query = st.text_input("ğŸ” í‚¤ì›Œë“œë¡œ IA ë¬¸ì„œ ê²€ìƒ‰", "")

# íŒ€ ëª©ë¡ ì¶”ì¶œ
def extract_teams(data):
    teams = set()
    for doc in data:
        for part in doc.get("parts", []):
            teams.add(part["part_name"])
    return sorted(list(teams))

teams = extract_teams(data)

# UI ìƒë‹¨ ì„ íƒ í•„í„° ì˜ì—­
with st.container():
    col1, col2 = st.columns([1, 2])
    with col1:
        selected_team = st.selectbox("íŒ€ ì„ íƒ (ì—°ê´€ëœ ë¬¸ì„œ í•„í„°ë§)", ["ì „ì²´"] + teams)

    def filter_by_team(data, team):
        if team == "ì „ì²´":
            return data
        return [doc for doc in data if any(p["part_name"] == team for p in doc.get("parts", []))]

    filtered_data = filter_by_team(data, selected_team)

    # ê²€ìƒ‰ í•„í„° ì ìš©
    if search_query:
        filtered_data = [doc for doc in filtered_data if search_query.lower() in doc["project_title"].lower() or search_query.lower() in doc["requirement"].lower()]

    with col2:
        ids = [doc["id"] + ": " + doc["project_title"] for doc in filtered_data]
        selected = st.selectbox("ê³¼ì œ ì„ íƒ", ids) if ids else None
        selected_id = selected.split(":")[0] if selected else None

# ì„ íƒëœ ë¬¸ì„œ í‘œì‹œ
doc = next((d for d in data if d["id"] == selected_id), None) if selected_id else None

if doc:
    st.subheader(f"ğŸ“ ê³¼ì œëª…: {doc['project_title']}")
    st.markdown(f"**ìš”êµ¬ì‚¬í•­:** {doc['requirement']}")

    st.divider()
    st.subheader("ğŸ”§ ì—°ê´€ íŒŒíŠ¸ë³„ ì •ë³´")
    for i, part in enumerate(doc["parts"], 1):
        with st.expander(f"íŒŒíŠ¸ {i}: {part['part_name']} ({part['role']})", expanded=True):
            st.markdown(f"- **ê¸°ëŠ¥:** {part['feature']}")
            st.markdown(f"- **ë‚´ìš©:** {part['content']}")

    matches = [f for f in os.listdir(WORD_DOCS_DIR) if f.startswith(f"{doc['id']}_") or f.endswith(".docx")]
    if matches:
        word_path = os.path.join(WORD_DOCS_DIR, matches[0])
        with open(word_path, "rb") as f:
            st.download_button(
                label="ğŸ“¥ IA Word ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ",
                data=f,
                file_name=matches[0],
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
    else:
        st.warning("ğŸ“„ í•´ë‹¹ ê³¼ì œì˜ Word ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
elif search_query:
    st.info("ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.error("ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
